{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "524e95b8-2b92-4373-bc85-1546eaa98637",
   "metadata": {
    "tags": []
   },
   "source": [
    "# RSLC to INSAR\n",
    "- This notebook converts RSLC data to GUNW products by running ISCE3's `insar.py`.\n",
    "- Uses the `isce3_src` kernel (created using [Create_Environments.ipynb](https://github.com/isce-framework/sds-ondemand/blob/main/environments/Create_Environments.ipynb)).\n",
    "- Can be ran locally (preferably on a GPU instance), or as a PCM job.\n",
    "\n",
    "# Parameters Cell\n",
    "This cell is marked `parameters`, indicating the variables within can substituted when running this notebook via `papermill`.\n",
    "- `rslc_1`: S3 url to the 1st RSLC to process.\n",
    "- `rslc_2`: S3 url to the 2nd RSLC to process.\n",
    "- `dem_s3_url`: S3 url to the DEM file to download.\n",
    "- `watermask_s3_url`: S3 url to the DEM file to download.\n",
    "- `gpu_enabled`: `1` to run using the GPU, `0` to use CPU instead. **Keep in mind that while disabling the GPU processing allows this notebook to be ran on an instance without a GPU, that does not mean the instance is a non-GPU instance.** To run on a non-GPU instance on PCM, submit the job to a CPU-only queue.\n",
    "- `infer_nisar_fname`: `1` to rename the final products to their NISAR filename, `0` to leave it as a concatenation of the two RSLC filenames.\n",
    "- `insar_config`: The runconfig passed to `insar.py`.\n",
    "\n",
    "### Upload parameters (PCM only)\n",
    "- `timestamp`: A time-string of the format `%Y%m%dT%H%M%S` indicating the time at which the job was submitted. This helps `pcm.py` find where the results of this job will be submitted when this notebook is ran as a PCM job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082b6cd-2ee0-4615-b597-9c6d61472b7b",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "rslc_1 = 's3://nisar-st-data-ondemand/ALOS-1-data/RSLC/ALPSRP118456700-L1.0.h5' # string\n",
    "rslc_2 = 's3://nisar-st-data-ondemand/ALOS-1-data/RSLC/ALPSRP224230660-L1.0.h5' # string\n",
    "dem_s3_url = 's3://nisar-st-data-ondemand/DEM-static/dem_Chile.tiff' # string\n",
    "watermask_s3_url = '' # string\n",
    "gpu_enabled = 1 # boolean\n",
    "infer_nisar_fname = 1 # boolean\n",
    "insar_config = '' # string\n",
    "timestamp = '20240131T0123456' # string\n",
    "\n",
    "# hysds specifications\n",
    "_time_limit = 172800\n",
    "_soft_time_limit = 172800\n",
    "_disk_usage = '60GB'\n",
    "_submission_type = 'iteration'\n",
    "_label = 'RSLC to INSAR PGE'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7628b5-6546-46d4-bfe2-0844ebf6c8dc",
   "metadata": {},
   "source": [
    "### Pre-processing of the Parameters to convert numbers or words into `boolean` True and False values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc1861-a531-412d-abb3-fe829713f26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean parameters because they must be specified as strings\n",
    "try:\n",
    "    if not isinstance(gpu_enabled, bool):\n",
    "        gpu_enabled = int(gpu_enabled) > 0\n",
    "except ValueError:\n",
    "    if instance(gpu_enabled, str):\n",
    "        gpu_enabled = gpu_enabled.lower() == 'true'\n",
    "    else:\n",
    "        gpu_enabled = False\n",
    "print(f'{gpu_enabled=}')\n",
    "\n",
    "try:\n",
    "    if not isinstance(infer_nisar_fname, bool):\n",
    "        infer_nisar_fname = int(infer_nisar_fname) > 0\n",
    "except ValueError:\n",
    "    if instance(infer_nisar_fname, str):\n",
    "        infer_nisar_fname = infer_nisar_fname.lower() == 'true'\n",
    "    else:\n",
    "        infer_nisar_fname = False\n",
    "print(f'{infer_nisar_fname=}')\n",
    "\n",
    "# Extraneous parameters\n",
    "focus_config = '' # string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00cf75c-75bc-4e88-b085-1c7a2b435d4b",
   "metadata": {},
   "source": [
    "# Functions for loading runconfig files and downloading from S3 buckets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea3b83-58cb-4baa-beb1-5ae272466ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import asf_search as asf\n",
    "import boto3\n",
    "import aws_uploader\n",
    "\n",
    "WORKING_DIR = os.getcwd()\n",
    "HOME_DIR = os.environ['HOME']\n",
    "NOTEBOOK_PGE_DIR = os.environ.get('NOTEBOOK_PGE_DIR', WORKING_DIR)\n",
    "ISCE3_BUILD_DIR = os.environ.get('ISCE3_BUILD_DIR', f'{HOME_DIR}/isce3/build')\n",
    "\n",
    "DOWNLOAD_DIR = os.path.join(WORKING_DIR, 'downloads')\n",
    "EXTRACT_DIR = os.path.join(WORKING_DIR, 'alos_data')\n",
    "OUTPUT_DIR = os.path.join(WORKING_DIR, 'output')\n",
    "PRODUCT_DIR = os.path.join(WORKING_DIR, 'product_path')\n",
    "\n",
    "os.makedirs(DOWNLOAD_DIR, exist_ok=True)\n",
    "os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(PRODUCT_DIR, exist_ok=True)\n",
    "\n",
    "if focus_config == '':\n",
    "    with open(os.path.join(NOTEBOOK_PGE_DIR, '../templates/focus.yaml'), 'r') as f:\n",
    "        FOCUS_YML = yaml.safe_load(f)\n",
    "else:\n",
    "    print('Using custom focus.py run config...')\n",
    "    FOCUS_YML = yaml.safe_load(focus_config)\n",
    "\n",
    "if insar_config == '':\n",
    "    with open(os.path.join(NOTEBOOK_PGE_DIR, '../templates/insar.yaml'), 'r') as f:\n",
    "        INSAR_YML = yaml.safe_load(f)\n",
    "else:\n",
    "    print('Using custom insar.py run config...')\n",
    "    INSAR_YML = yaml.safe_load(insar_config)\n",
    "\n",
    "print(WORKING_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497300a6-bbe6-410f-8164-4d635b2e1639",
   "metadata": {},
   "source": [
    "# Run ISCE3 Python Scripts\n",
    "This cell runs the python scripts:\n",
    "- `insar.py`: Converts RSLC -> GUNW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69116c4-7783-4648-bdbe-ee9a3966b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse\n",
    "import isce3_config\n",
    "\n",
    "# Download the RSLCs from S3\n",
    "dest = []\n",
    "for link in [rslc_1, rslc_2]:\n",
    "    download_f = os.path.join(DOWNLOAD_DIR, os.path.basename(urlparse(link).path))\n",
    "    if not os.path.exists(download_f):\n",
    "        aws_uploader.AWS.download_s3(link, download_f)\n",
    "        if os.path.exists(download_f):\n",
    "            print(f'Downloaded: {download_f}')\n",
    "        else:\n",
    "            print(f'==========DOWNLOAD FAILED: {download_f}==========')\n",
    "    else:\n",
    "        print(f'{download_f} already exists, now continuing...')\n",
    "    dest.append(download_f)\n",
    "\n",
    "# Grab the bounding box for the DEM and water mask\n",
    "bb1 = isce3_config.h5parse.get_bounds(dest[0])\n",
    "bb2 = isce3_config.h5parse.get_bounds(dest[1])\n",
    "bbox = isce3_config.BoundingBox(west=min(bb1.west, bb2.west),\n",
    "                                south=min(bb1.south, bb2.south),\n",
    "                                east=max(bb1.east, bb2.east),\n",
    "                                north=max(bb1.north, bb2.north))\n",
    "\n",
    "print('Union of Bounding Boxes (Auto Determined, Used if no DEM/Watermask Specified):')\n",
    "print(bbox)\n",
    "\n",
    "# Download the DEM locally\n",
    "if isinstance(dem_s3_url, str) and dem_s3_url != '':\n",
    "    dem_f = isce3_config.download_dem(dem_s3_url, DOWNLOAD_DIR)\n",
    "else:\n",
    "    print(f'DEM input ({dem_s3_url}) was not specified, downloading DEM via stage_dem.py instead.')\n",
    "\n",
    "    dem_vrt_f = os.path.join(PRODUCT_DIR, 'dem.vrt')\n",
    "    dem_f = os.path.join(PRODUCT_DIR, 'dem_0.tiff')\n",
    "\n",
    "    # Stage the DEM using the combined bounds for dem_tiff_f\n",
    "    _cmd_stage_dem = f'mamba run -n isce3_src --live-stream python {ISCE3_BUILD_DIR}/packages/nisar/workflows/stage_dem.py --margin=10 -b {bbox.west} {bbox.south} {bbox.east} {bbox.north} -o {dem_vrt_f}'\n",
    "    print(f'Executing:\\n    {_cmd_stage_dem}')\n",
    "    !{_cmd_stage_dem}\n",
    "\n",
    "# Download the Watermask locally\n",
    "if isinstance(watermask_s3_url, str) and watermask_s3_url != '':\n",
    "    watermask_f = isce3_config.download_dem(watermask_s3_url, DOWNLOAD_DIR)\n",
    "else:\n",
    "    print(f'DEM input ({watermask_s3_url}) was not specified, downloading DEM via stage_watermask.py instead.')\n",
    "\n",
    "    watermask_vrt_f = os.path.join(PRODUCT_DIR, 'WATERMASK.vrt')\n",
    "    watermask_f = os.path.join(PRODUCT_DIR, 'WATERMASK_0.tiff')\n",
    "\n",
    "    # Stage the DEM using the combined bounds for watermask_tiff_f\n",
    "    _cmd_stage_watermask = f'mamba run -n isce3_src --live-stream python {ISCE3_BUILD_DIR}/packages/nisar/workflows/stage_watermask.py --margin=10 -b {bbox.west} {bbox.south} {bbox.east} {bbox.north} -o {watermask_vrt_f}'\n",
    "    print(f'Executing:\\n    {_cmd_stage_watermask}')\n",
    "    !{_cmd_stage_watermask}\n",
    "\n",
    "# Run INSAR\n",
    "b1 = os.path.basename(os.path.splitext(dest[0])[0])\n",
    "b2 = os.path.basename(os.path.splitext(dest[1])[0])\n",
    "yml_path = os.path.join(OUTPUT_DIR, 'insar_final.yml')\n",
    "output_f = os.path.join(PRODUCT_DIR, f'{b1}_{b2}.h5')\n",
    "isce3_config.write_insar_config(INSAR_YML,\n",
    "                                dest[0],\n",
    "                                dest[1],\n",
    "                                dem_f,\n",
    "                                watermask_f,\n",
    "                                yml_path,\n",
    "                                gpu_enabled,\n",
    "                                output_f)\n",
    "print(f'{os.path.exists(yml_path)=}')\n",
    "print(f'Now running insar.py to generate {output_f}...')\n",
    "print(f'Executing:\\n    mamba run --live-stream -n isce3_src python {ISCE3_BUILD_DIR}/packages/nisar/workflows/insar.py {yml_path}')\n",
    "!mamba run --no-capture-output -p /home/jovyan/test/.conda python {ISCE3_BUILD_DIR}/packages/nisar/workflows/insar.py {yml_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b3fc6-62b5-49a6-82d8-b7dccdcccdc7",
   "metadata": {},
   "source": [
    "# Automatic Stage Out for PCM Jobs (r4.0.0)\n",
    "This routine creates a folder which matches the regex:\n",
    "\n",
    "#### GUNW\n",
    "**Example:** `NISAR_L2_PR_GUNW_000_000_Z_000_000_0000_HH_20240131T000000_20250131T000000_20250131T000001_20250131T000002_0A1B2C_A_F_Z_000`\n",
    "```\n",
    "(?P<id>NISAR_L2_(?P<processing_type>PR)_GUNW_(?P<reference_cycle_number>\\d{3})_(?P<relative_orbit_number>\\d{3})_(?P<Direction>\\w)_(?P<TrackFrame>\\d{3})_(?P<secondary_cycle_number>\\d{3})_(?P<radar_processing_mode>\\d{4})_(?P<Polarization>\\w{2})_(?P<RefRadarStartDateTime>(?P<year>\\d{4})(?P<month>\\d{2})(?P<day>\\d{2})T\\d{6})_(?P<RefRadarStopDateTime>\\d{8}T\\d{6})_(?P<SecRadarStartDateTime>\\d{8}T\\d{6})_(?P<SecRadarStopDateTime>\\d{8}T\\d{6})_(?P<composite_release_id>\\w{6})_(?P<Fidelity>\\w)_(?P<CoverageIndicator>[F|P])_(?P<processing_center>\\w)_(?P<product_counter>\\d{3}))$\n",
    "```\n",
    "\n",
    "This enables PCM to automatically upload the results of this notebook to the `s3://nisar-{system_name}-rs-ondemand` bucket.\n",
    "\n",
    "`system_name` is one of the following:\n",
    "- `st` (for Science Team)\n",
    "- `adt` (for ADT)\n",
    "- `iot` (for IOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2ee47c-34a8-4467-940b-4c4a6914532d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import json\n",
    "\n",
    "# Grab some appropriate values for PCM to automatically stage out\n",
    "polarization = 'HH'\n",
    "regex_name = isce3_config.GUNW_FORMAT.format(\n",
    "    polarization=polarization,\n",
    "    timestamp=timestamp)\n",
    "auto_output_dir = os.path.join(WORKING_DIR, regex_name)\n",
    "product_suffix = os.path.basename(output_f)\n",
    "product_base_fname = os.path.splitext(product_suffix)[0]\n",
    "\n",
    "# Create the automatic stage-out directory\n",
    "!mkdir -p {auto_output_dir}\n",
    "!cp {WORKING_DIR}/*-output.ipynb {auto_output_dir}\n",
    "!cp {WORKING_DIR}/*.txt {auto_output_dir}\n",
    "!cp {WORKING_DIR}/*.json {auto_output_dir}\n",
    "!mv {yml_path} {auto_output_dir}\n",
    "!touch {auto_output_dir}/{product_base_fname}.txt\n",
    "\n",
    "# Move the products\n",
    "infer_failed = False\n",
    "if infer_nisar_fname:\n",
    "    print('Now inferring NISAR filename for INSAR products...')\n",
    "    infer_list = []\n",
    "    try:\n",
    "        for iter_fname in os.scandir(PRODUCT_DIR):\n",
    "            if iter_fname.is_file() and iter_fname.path.endswith(product_suffix):\n",
    "                inferred_prod_name = isce3_config.h5parse.infer_nisar_name(iter_fname.path)\n",
    "                print(f'Inferred NISAR filename:\\n    - {iter_fname.path} -> {inferred_prod_name}')\n",
    "                infer_list.append([iter_fname.path, os.path.join(auto_output_dir, inferred_prod_name)])\n",
    "        for insar_path_pair in infer_list:\n",
    "            print(f'Now moving:\\n    - {insar_path_pair[0]} -> {insar_path_pair[1]}')\n",
    "            os.rename(insar_path_pair[0], insar_path_pair[1])\n",
    "    except Exception as e:\n",
    "        print('An error occured while trying to infer a NISAR filename. Using standard name instead.')\n",
    "        print(e)\n",
    "        infer_failed = True\n",
    "\n",
    "if not infer_nisar_fname or infer_failed:\n",
    "    #!mv {PRODUCT_DIR}/*{product_suffix} {auto_output_dir}\n",
    "    print(f'mv {PRODUCT_DIR}/*{product_suffix} {auto_output_dir}')\n",
    "\n",
    "# Move the new path variables to avoid confusion\n",
    "yml_path = os.path.join(auto_output_dir, os.path.basename(yml_path))\n",
    "output_f = os.path.join(auto_output_dir, os.path.basename(output_f))\n",
    "\n",
    "# Create metadata files for the automatic stage-out directory\n",
    "with open(os.path.join(auto_output_dir, f'{regex_name}.met.json'), 'w', encoding='utf-8') as f:\n",
    "    content = {\n",
    "        'polarization': polarization,\n",
    "    }\n",
    "    f.write(json.dumps(content))\n",
    "with open(os.path.join(auto_output_dir, f'{regex_name}.dataset.json'), 'w', encoding='utf-8') as f:\n",
    "    content = {\n",
    "         'version': 'v1.0',\n",
    "         'label': 'This is purely an EXAMPLE metadata file, the values in this file are not representative of this product.',\n",
    "         'location': {\n",
    "           'type': 'polygon',\n",
    "           'coordinates': [\n",
    "             [\n",
    "                [-122.9059682940358,40.47090915967475],\n",
    "                [-121.6679748715316,37.84406528996276],\n",
    "                [-120.7310161872557,38.28728069813177],\n",
    "                [-121.7043611684245,39.94137004454238],\n",
    "                [-121.9536916840953,40.67097860759095],\n",
    "                [-122.3100379696548,40.7267890636145],\n",
    "                [-122.7640648263371,40.5457010812299],\n",
    "                [-122.9059682940358,40.47090915967475]\n",
    "              ]\n",
    "            ]\n",
    "        },\n",
    "        'starttime': '2017-01-01T00:00:00',\n",
    "        'endtime': '2017-01-01T00:05:00',\n",
    "    }\n",
    "    f.write(json.dumps(content))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "isce3_src",
   "language": "python",
   "name": "isce3_src"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "toc-autonumbering": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
